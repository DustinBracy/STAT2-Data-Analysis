---
title: "Data Analysis Project"
author: "D. Bracy , H.H. Nguyen, S.Purvis"
date: "3/11/2020"
output:
  word_document: 
    reference_docx: "wordStyleRef.docx"
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
library(caret)
library(corrplot)
library(GGally)

# wordStyleRef style changes:
## Set margins to .5"
## Heading 1 creates page break before line
## Heading 2 remove space before
## Heading 5 centers text (#####) 

```


## R Markdown

Suggested Downtime Activities:  

1. Data cleaning (handle missing?,  train/test split logistics:  you want a good balance of Y/N in your train)
2. summary statistics (the ones I kept complaining about on Project 1)
3. EDA (basic boxplots, scatterplots, bar charts etc to see how things relate to the response, PCA tool),
4. Maybe play around and fit a few LDA models with continuous stuff.

##### ![caption](https://whitelabel.2u.com/cdn/v1/smu-mds/compass-dark.svg){width=10%}


Note this is just a syntax example. Since we don't have a local picture to use, this will show nothing in the word doc.  Also worth noting is the H5 marking, which centers the image.


#### Latex examples:

$$Variance Ratio=  \frac{(σ_{max})^2}{(σ_{min} )^2} = \frac{2.84^2}{1.20^2} =5.6$$

$$log(ReportDeliveryTime) = SchedFreq + HourOfDay + DayOfMonth + ReportCategory + Server$$



```{r read data}
#reading in 'Bank Additional' file
bank = read.csv("./DataSets/bank-additional.csv",header = TRUE, sep = ";")
str(bank)
summary(bank)
sum(is.na(bank))

#reading in 'Bank Additional Full' file
bankfull = read.csv("./DataSets/bank-additional-full.csv",header = TRUE, sep = ";")
str(bankfull)
summary(bankfull)
sum(is.na(bankfull))
```


```{r Feature Engineering}
#Create id to merge later
#bankfull$id <- seq.int(nrow(bankfull))

#Onehot encode categorical variables to binary:
dmy <- dummyVars(" ~ .", data = bankfull)
trsf <- data.frame(predict(dmy, newdata = bankfull))
#bank2 <- inner_join(bankfull, trsf, by = "id")

#Remove binary encoded response
trsf$y <- ifelse(trsf$y.no == 1, 0, 1)
bankbin <- subset(trsf, select = -c(y.no, y.yes))


```


## Correlation Analysis
Here we are looking to see improvement gained from feature engineering and to ensure we select features which have high correlation with our response variable for use in our machine learning algorthims.

<center>

![Correlation Plot of all Rdata features](./figures/CorrPlot.png) 

</center>


```{r build Correlation Plot, include=FALSE}
# Corrplot function from: http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram
# Vignette for corrplot is also useful

data.cor <- cor(bankbin)

# mat : is a matrix of data
# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(bankbin)

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))

# Build corrPlot.png ordered by Angular order of Eigenvectors
png(height=1100, width=1200, pointsize=15, file="./figures/corrPlot.png")
corrplot(data.cor, 
         method="circle", 
         order="AOE",
         tl.col="black", 
         type="full", 
         tl.cex = 1, 
         p.mat = p.mat, 
         sig.level = 0.01, 
         insig = "blank")
ggsave("./figures/corrPlot.png", units="in", width=5, height=4, dpi=600)
dev.off()

```


```{r EDA}


df <- bank # input dataframes for plots

df %>% ggplot(aes(y, age)) + geom_boxplot() + coord_flip()
df %>% ggplot(aes(job, y, fill=y)) + geom_col()
df %>% ggplot(aes(marital, y, fill=y)) + geom_col()
df %>% ggplot(aes(education, y,  fill=y)) + geom_col()
df %>% ggplot(aes(default, y,  fill=y)) + geom_col()
df %>% ggplot(aes(housing, y,  fill=y)) + geom_col()
df %>% ggplot(aes(loan, y,  fill=y)) + geom_col()
df %>% ggplot(aes(contact, y,  fill=y)) + geom_col()
df %>% ggplot(aes(month, y,  fill=y)) + geom_col()
df %>% ggplot(aes(day_of_week, y,  fill=y)) + geom_col()
df %>% ggplot(aes(y, duration)) + geom_boxplot() + coord_flip()
df %>% ggplot(aes(campaign, y,  fill=y)) + geom_col()
df %>% ggplot(aes(y, campaign)) + geom_boxplot() + coord_flip()

df %>% ggplot(aes(pdays, y,  fill=y)) + geom_point()

df %>% ggplot(aes(previous, y,  fill=y)) + geom_col()
df %>% ggplot(aes(poutcome, y,  fill=y)) + geom_col()


df %>% ggplot(aes(emp.var.rate, y,  fill=y)) + geom_col()
df %>% ggplot(aes(y, emp.var.rate)) + geom_boxplot() + coord_flip()

df %>% ggplot(aes(cons.price.idx, y,  fill=y)) + geom_col()
df %>% ggplot(aes(y, cons.price.idx)) + geom_boxplot() + coord_flip()


df %>% ggplot(aes(cons.conf.idx, y,  fill=y)) + geom_col()
df %>% ggplot(aes(y, cons.conf.idx)) + geom_boxplot() + coord_flip()


df %>% ggplot(aes(euribor3m, y,  fill=y)) + geom_col()
df %>% ggplot(aes(y, nr.employed)) + geom_boxplot() + coord_flip()

df %>% ggplot(aes(nr.employed, y,  fill=y)) + geom_col()
df %>% ggplot(aes(y, nr.employed)) + geom_boxplot() + coord_flip()
```

```{r}
#additional EDA Graphics
ggpairs(df)
ggcorr(df)

#Duration appears to matter - looking at the day of the week too. It appears you get a Yes on Thursday faster than any other day of the week.
df %>% ggplot(aes(y, duration)) + geom_boxplot() + coord_flip() + facet_grid(day_of_week ~ .)

df %>% ggplot(aes(euribor3m, nr.employed, color=y)) + geom_point()


```





```{r LDA analysis with bankcont}

# Select only continuous variables:
bankCont <- dplyr::select(bankfull, c('age','duration', 'campaign', 'pdays', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed','y'))
bankCont$age <- as.numeric(bankCont$age)
bankCont$duration <- as.numeric(bankCont$duration)
bankCont$campaign <- as.numeric(bankCont$campaign)
bankCont$pdays <- as.numeric(bankCont$pdays)


mylda<-lda(y~age+duration+ campaign+ pdays+ cons.price.idx+ cons.conf.idx+ euribor3m+ nr.employed, data=bankCont)
pred<-predict(mylda,newdata=bankCont)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-bankCont$y
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/1000
ME



```


```{r LDA analysis with bankbin}

mylda<-lda(y~., data=bankbin)
pred<-predict(mylda,newdata=bankbin)$class  #Predictions can come in many forms, the class form provides the categorical level of your response.
Truth<-bankbin$y
x<-table(pred,Truth) # Creating a confusion matrix
x
#Missclassification Error
ME<-(x[2,1]+x[1,2])/1000
ME



```


```{r PCA Analysis with bankCont}

pc.bankCont<-prcomp(bankCont[,-9],scale.=TRUE)
pc.bankCont.scores<-pc.bankCont$x

#Adding the response column to the PC's data frame
pc.bankCont.scores<-data.frame(pc.bankCont.scores)
pc.bankCont.scores$y<-bankCont$y

pc.bankCont.scores

#Use ggplot2 to plot the first few pc's
ggplot(data = pc.bankCont.scores, aes(x = PC1, y = PC2)) +
  geom_point(aes(col=y), size=1)+
  ggtitle("PCA of Subscriptions")

ggplot(data = pc.bankCont.scores, aes(x = PC2, y = PC3)) +
  geom_point(aes(col=y), size=1)+
  ggtitle("PCA of Subscriptions")


```

```{r PCA Analysis with bankbin}

pc.bankbin<-prcomp(bankbin[,-64],scale.=TRUE)
pc.bankbin.scores<-pc.bankbin$x

#Adding the response column to the PC's data frame
pc.bankbin.scores<-data.frame(pc.bankbin.scores)
pc.bankbin.scores$y<-bankbin$y

pc.bankbin.scores

#Use ggplot2 to plot the first few pc's
ggplot(data = pc.bankbin.scores, aes(x = PC1, y = PC2)) +
  geom_point(aes(col=y), size=1)+
  ggtitle("PCA of Subscriptions")

ggplot(data = pc.bankbin.scores, aes(x = PC2, y = PC3)) +
  geom_point(aes(col=y), size=1)+
  ggtitle("PCA of Subscriptions")

ggplot(data = pc.bankbin.scores, aes(x = PC3, y = PC4)) +
  geom_point(aes(col=y), size=1)+
  ggtitle("PCA of Subscriptions")

```


```{r}
library(caret) 
library(e1071)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(caTools)
library(descr)
#########################################################
# Sampling the dataset into training data and test data:
#############################################################

set.seed(1234)
splitPerc = .75
index = sample(1:dim(bankCont)[1],round(splitPerc * dim(bankCont)[1]))
#index<-sample(1:dim(Auto2)[1],192,replace=F)
traindata<-bankCont[index,]
testdata<-bankCont[-index,]

  


# Classification and Regression Trees
bank.cart<-rpart(y ~ ., traindata , method = 'class')

#par(mfrow=c(1,1))
#fancyRpartPlot(bank.cart , digits=2 , palettes = c("Purples", "Oranges"))

#predict
cart_pred <- predict( bank.cart , testdata , type = "class")
cart_prob <- predict( bank.cart , testdata , type = "prob")

# Confusion matrix
confusionMatrix(cart_pred , testdata$y)

### Cross table validation for CART
CrossTable(testdata$y, cart_pred,
          prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
          dnn = c('actual default', 'predicted default'))
```



```{r knn}
#Implementing KNN
###########################################
bank.knn <- train(y ~ ., data = traindata, method = "knn", 
                  maximize = TRUE,
                  trControl = trainControl(method = "cv", number = 10),
                  preProcess=c("center", "scale"))

predictedkNN <- predict(bank.knn , newdata = testdata)
confusionMatrix(predictedkNN , testdata$y)

### Cross table validation for KNN
CrossTable(testdata$y, predictedkNN,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```






